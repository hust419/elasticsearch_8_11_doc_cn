##### 日志记录

您可以使用Elasticsearch的应用程序日志来监控集群并诊断问题。如果将Elasticsearch作为服务运行，则日志的默认位置根据您的平台和安装方法而异：

- 对于Linux .tar.gz安装，Elasticsearch将日志写入$ES_HOME/logs。

在升级期间，![](https://www.yuque.com/api/services/graph/generate_redirect/latex?ES_HOME%E4%B8%AD%E7%9A%84%E6%96%87%E4%BB%B6%E6%9C%89%E8%A2%AB%E5%88%A0%E9%99%A4%E7%9A%84%E9%A3%8E%E9%99%A9%E3%80%82%E5%9C%A8%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%AD%EF%BC%8C%E5%BC%BA%E7%83%88%E5%BB%BA%E8%AE%AE%E5%B0%86path.logs%E8%AE%BE%E7%BD%AE%E4%B8%BA#card=math&code=ES_HOME%E4%B8%AD%E7%9A%84%E6%96%87%E4%BB%B6%E6%9C%89%E8%A2%AB%E5%88%A0%E9%99%A4%E7%9A%84%E9%A3%8E%E9%99%A9%E3%80%82%E5%9C%A8%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%AD%EF%BC%8C%E5%BC%BA%E7%83%88%E5%BB%BA%E8%AE%AE%E5%B0%86path.logs%E8%AE%BE%E7%BD%AE%E4%B8%BA&id=OSO2e)ES_HOME之外的位置。请参阅路径设置。

如果从命令行运行Elasticsearch，则Elasticsearch将日志打印到标准输出（stdout）。

日志配置

Elastic强烈建议使用默认提供的Log4j 2配置。

Elasticsearch使用Log4j 2进行日志记录。 Log4j 2可以使用log4j2.properties文件进行配置。 Elasticsearch公开了三个属性，![](https://www.yuque.com/api/services/graph/generate_redirect/latex?%7Bsys%3Aes.logs.base_path%7D%E3%80%81#card=math&code=%7Bsys%3Aes.logs.base_path%7D%E3%80%81&id=UuCF8){sys:es.logs.cluster_name}和![](https://www.yuque.com/api/services/graph/generate_redirect/latex?%7Bsys%3Aes.logs.node_name%7D%EF%BC%8C%E5%8F%AF%E4%BB%A5%E5%9C%A8%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E4%B8%AD%E5%BC%95%E7%94%A8%E4%BB%A5%E7%A1%AE%E5%AE%9A%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6%E7%9A%84%E4%BD%8D%E7%BD%AE%E3%80%82%E5%B1%9E%E6%80%A7#card=math&code=%7Bsys%3Aes.logs.node_name%7D%EF%BC%8C%E5%8F%AF%E4%BB%A5%E5%9C%A8%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E4%B8%AD%E5%BC%95%E7%94%A8%E4%BB%A5%E7%A1%AE%E5%AE%9A%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6%E7%9A%84%E4%BD%8D%E7%BD%AE%E3%80%82%E5%B1%9E%E6%80%A7&id=Ki1uf){sys:es.logs.base_path}将解析为日志目录，![](https://www.yuque.com/api/services/graph/generate_redirect/latex?%7Bsys%3Aes.logs.cluster_name%7D%E5%B0%86%E8%A7%A3%E6%9E%90%E4%B8%BA%E9%9B%86%E7%BE%A4%E5%90%8D%E7%A7%B0%EF%BC%88%E5%9C%A8%E9%BB%98%E8%AE%A4%E9%85%8D%E7%BD%AE%E4%B8%AD%E7%94%A8%E4%BD%9C%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6%E5%90%8D%E7%9A%84%E5%89%8D%E7%BC%80%EF%BC%89%EF%BC%8C#card=math&code=%7Bsys%3Aes.logs.cluster_name%7D%E5%B0%86%E8%A7%A3%E6%9E%90%E4%B8%BA%E9%9B%86%E7%BE%A4%E5%90%8D%E7%A7%B0%EF%BC%88%E5%9C%A8%E9%BB%98%E8%AE%A4%E9%85%8D%E7%BD%AE%E4%B8%AD%E7%94%A8%E4%BD%9C%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6%E5%90%8D%E7%9A%84%E5%89%8D%E7%BC%80%EF%BC%89%EF%BC%8C&id=u5v0v){sys:es.logs.node_name}将解析为节点名称（如果节点名称已明确设置）。

例如，如果您的日志目录（path.logs）是/var/log/elasticsearch，而您的集群命名为production，则![](https://www.yuque.com/api/services/graph/generate_redirect/latex?%7Bsys%3Aes.logs.base_path%7D%E5%B0%86%E8%A7%A3%E6%9E%90%E4%B8%BA%2Fvar%2Flog%2Felasticsearch%EF%BC%8C%E8%80%8C#card=math&code=%7Bsys%3Aes.logs.base_path%7D%E5%B0%86%E8%A7%A3%E6%9E%90%E4%B8%BA%2Fvar%2Flog%2Felasticsearch%EF%BC%8C%E8%80%8C&id=i4g6m){sys:es.logs.base_path}![](https://www.yuque.com/api/services/graph/generate_redirect/latex?%7Bsys%3Afile.separator%7D#card=math&code=%7Bsys%3Afile.separator%7D&id=fLbRH){sys:es.logs.cluster_name}.log将解析为/var/log/elasticsearch/production.log。

```yaml
######## 服务器JSON ############################
appender.rolling.type = RollingFile （1）
appender.rolling.name = rolling
appender.rolling.fileName = ${sys:es.logs.base_path}${sys:file.separator}${sys:es.logs.cluster_name}_server.json （2）
appender.rolling.layout.type = ECSJsonLayout （3）
appender.rolling.layout.dataset = elasticsearch.server （4）
appender.rolling.filePattern = ${sys:es.logs.base_path}${sys:file.separator}${sys:es.logs.cluster_name}-%d{yyyy-MM-dd}-%i.json.gz（5） 
appender.rolling.policies.type = Policies
appender.rolling.policies.time.type = TimeBasedTriggeringPolicy （6）
appender.rolling.policies.time.interval = 1 （7）
appender.rolling.policies.time.modulate = true （8）
appender.rolling.policies.size.type = SizeBasedTriggeringPolicy （9）
appender.rolling.policies.size.size = 256MB （10）
appender.rolling.strategy.type = DefaultRolloverStrategy
appender.rolling.strategy.fileIndex = nomax
appender.rolling.strategy.action.type = Delete （11）
appender.rolling.strategy.action.basepath = ${sys:es.logs.base_path}
appender.rolling.strategy.action.condition.type = IfFileName  （12）
appender.rolling.strategy.action.condition.glob = ${sys:es.logs.cluster_name}-* （13）
appender.rolling.strategy.action.condition.nested_condition.type = IfAccumulatedFileSize （14）
appender.rolling.strategy.action.condition.nested_condition.exceeds = 2GB （15）
################################################
```

1. 配置RollingFile appender
2. 将日志记录到/var/log/elasticsearch/production_server.json
3. 使用JSON布局。
4. 数据集是一个标志，用于在解析时更轻松地区分不同类型的日志。
5. 将日志滚动到/var/log/elasticsearch/production-yyyy-MM-dd-i.json；每次滚动时，日志将被压缩并且i将增加。
6. 使用基于时间的滚动策略。
7. 按天滚动日志。
8. 按天对齐滚动（与每隔二十四小时滚动不同）。
9. 使用基于大小的滚动策略。
10. 在256 MB后滚动日志。
11. 在滚动日志时使用删除操作。
12. 仅在匹配文件模式的情况下删除日志。
13. 该模式仅用于删除主要日志。
14. 仅在累积的压缩日志过多时才删除。
15. 对于累积的压缩日志的大小条件为2 GB。

```yaml
######## 服务器 - 旧样式模式 ###########
appender.rolling_old.type = RollingFile
appender.rolling_old.name = rolling_old
appender.rolling_old.fileName = ${sys:es.logs.base_path}${sys:file.separator}${sys:es.logs.cluster_name}_server.log 
appender.rolling_old.layout.type = PatternLayout
appender.rolling_old.layout.pattern = [%d{ISO8601}][%-5p][%-25c{1.}] [%node_name]%marker %m%n
appender.rolling_old.filePattern = ${sys:es.logs.base_path}${sys:file.separator}${sys:es.logs.cluster_name}-%d{yyyy-MM-dd}-%i.old_log.gz
```

_旧样式模式附加器的配置。这些日志将保存在.log文件中，如果存档，则将在.log.gz文件中。请注意，这些应被视为不推荐使用，并且将来可能会被移除。_
_Log4j的配置解析会因任何多余的空格而混淆；如果在此页面上复制和粘贴任何Log4j设置，或者一般输入任何Log4j配置，请务必修剪任何前导和尾随空格。_
_请注意，您可以在appender.rolling.filePattern中使用.gz替换.zip，以使用zip格式压缩滚动的日志。如果删除.gz扩展名，则在滚动时不会压缩日志。如果要保留指定时间的日志文件，可以使用具有删除操作的翻转策略。_

```yaml
appender.rolling.strategy.type = DefaultRolloverStrategy (1)
appender.rolling.strategy.action.type = Delete (2)
appender.rolling.strategy.action.basepath = ${sys:es.logs.base_path} (3)
appender.rolling.strategy.action.condition.type = IfFileName (4)
appender.rolling.strategy.action.condition.glob = ${sys:es.logs.cluster_name}-*(5) 
  appender.rolling.strategy.action.condition.nested_condition.type = IfLastModified (6)
appender.rolling.strategy.action.condition.nested_condition.age = 7D (7)
```

1. 配置DefaultRolloverStrategy
2. 配置用于处理翻转的删除操作
3. Elasticsearch日志的基本路径
4. 处理翻转时应用的条件
5. 删除与glob ${sys:es.logs.cluster_name}-*匹配的基本路径下的文件；这是日志文件滚动到的地方；这是为了只删除已滚动的Elasticsearch日志，而不删除弃用和慢日志
6. 应用于匹配glob的文件的嵌套条件
7. 保留日志七天

可以加载多个配置文件（在这种情况下它们将被合并），只要它们被命名为log4j2.properties并且具有Elasticsearch配置目录作为祖先；这对于插件公开其他日志记录器的情况很有用。logger部分包含Java包及其相应日志级别。appender部分包含日志的目的地。有关如何自定义日志记录和所有支持的附加器的详细信息，请参阅Log4j文档。

##### 配置日志级别

Elasticsearch源代码中的每个Java包都有一个相关的记录器。例如，org.elasticsearch.discovery包有logger.org.elasticsearch.discovery，用于与发现过程相关的日志。

要获取更多或更少详细的日志，使用集群更新设置API更改相关记录器的日志级别。每个记录器接受Log4j 2的内置日志级别，从最不详细到最详细：OFF、FATAL、ERROR、WARN、INFO、DEBUG和TRACE。默认的日志级别是INFO。以更高的详细级别（DEBUG和TRACE）记录的消息仅供专家使用。

```shell
PUT /_cluster/settings
{
    "persistent": {
        "logger.org.elasticsearch.discovery": "DEBUG"
    }
}
```

将记录器的详细级别重置为其默认级别，将记录器设置为null：

```shell
PUT /_cluster/settings
{
  "persistent": {
    "logger.org.elasticsearch.discovery": null
  }
}
```

更改日志级别的其他方法包括：

在elasticsearch.yml中：

```yaml
logger.org.elasticsearch.discovery: DEBUG
```

这在单个节点上调试问题时最合适。

在log4j2.properties中：

```yaml
logger.discovery.name = org.elasticsearch.discovery
logger.discovery.level = debug
```

这在已经因其他原因需要更改Log4j 2配置时最合适。例如，您可能希望将特定记录器的日志发送到另一个文件。然而，这些用例很少见。

##### 弃用日志

Elasticsearch还将弃用日志写入日志目录。这些日志记录了在使用已弃用的Elasticsearch功能时的消息。您可以使用弃用日志在将Elasticsearch升级到新的主要版本之前更新应用程序。

默认情况下，Elasticsearch在1GB时滚动和压缩弃用日志。默认配置保留最多五个日志文件：四个滚动日志和一个活动日志。

Elasticsearch以CRITICAL级别发出弃用日志消息。这些消息表明将在下一个主要版本中删除已使用的弃用功能。WARN级别的弃用日志消息表示使用了一个不太关键的功能，它不会在下一个主要版本中删除，但可能会在将来删除。

要停止写入弃用日志消息，请在log4j2.properties中将logger.deprecation.level设置为OFF：

```yaml
logger.deprecation.level = OFF
```

或者，您可以动态更改日志级别：

```json
PUT /_cluster/settings
{
  "persistent": {
    "logger.org.elasticsearch.deprecation": "OFF"
  }
}
```

有关配置日志级别的信息，请参阅配置日志级别。

如果使用X-Opaque-Id作为HTTP标头，您可以确定触发弃用功能的是什么。用户ID包含在deprecation JSON日志中的X-Opaque-ID字段中。

```json
{
  "type": "deprecation",
  "timestamp": "2019-08-30T12:07:07,126+02:00",
  "level": "WARN",
  "component": "o.e.d.r.a.a.i.RestCreateIndexAction",
  "cluster.name": "distribution_run",
  "node.name": "node-0",
  "message": "[types removal] Using include_type_name in create index requests is deprecated. The parameter will be removed in the next major version.",
  "x-opaque-id": "MY_USER_ID",
  "cluster.uuid": "Aq-c-PAeQiK3tfBYtig9Bw",
  "node.id": "D7fUYfnfTLa2D7y-xw6tZg"
}
```

如果设置cluster.deprecation_indexing.enabled为true，则可以将弃用日志索引到.logs-deprecation.elasticsearch-default数据流中。

##### 弃用日志限流

弃用日志根据弃用功能密钥和x-opaque-id进行去重，以便如果重复使用某个功能，它不会使弃用日志超负荷。这适用于索引的弃用日志和写入日志文件的日志。您可以通过将cluster.deprecation_indexing.x_opaque_id_used.enabled更改为false来禁用在限流中使用x-opaque-id，有关更多详细信息，请参阅此类javadoc。

##### JSON日志格式

为了更轻松地解析Elasticsearch日志，现在以JSON格式打印日志。这由Log4J布局
